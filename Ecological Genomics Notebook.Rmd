# Ecological Genomics Nothebook

## Author: Jorge A. Ruiz-Arocho
### Affiliation: University of Vermont, PSS  
### E-mail contact: jorge.ruizarocho@uvm.edu


### Start Date: 2020-01-13
### End Date: 2020-05-08
### Project Descriptions:   





# Table of Contents:   
* [Entry 1: 2020-01-13, Introductory Class](#id-section1)
* [Entry 2: 2020-01-15, First Info Updates](#id-section2)
* [Entry 3: 2020-01-22, Second Info Updates](#id-section3)
* [Entry 4: 2020-01-27, First Paper Discussion](#id-section9)
* [Entry 5: 2020-01-29, Second Tutorial](#id-section10)
* [Entry 6: 2020-02-03, Second Paper Dicsussion](#id-section11)
* [Entry 7: 2020-02-05, Third Tutorial](#id-section18)
* [Entry 8: 2020-02-10, Third Paper Discussion](#id-section19)
* [Entry 9: 2020-02-12, Fourth Tutorial](#id-section20)
* [Entry 10: 2020-02-19, Fifth Tutorial](#id-section21)
* [Entry 11: 2020-02-11, Fourth Paper Discussion](#id-section22)
* [Entry 12: 2020-02-26, Transcriptomics Day One](#id-section23)
* [Entry 13: 2020-03-02, Fifth Paper Discussion](#id-section24)
* [Entry 14: 2020-03-04, Transcriptomics Day Two](#id-section25)
* [Entry 15: 2020-03-18, Transcriptomic Day Three](#id-section26)
* [Entry 16: 2020-03-23, Sixth Paper Discussion](#id-section17)
* [Entry 17: 2020-03-25, First Epigenomic Section](#id-section28)
* [Entry 18: 2020-03-30, Seventh Paper Discussion](#id-section1000)
* [Entry 19: 2020-04-01, Second Epigenomic Section](#id-section30)
* [Entry 31: 2020-02-24, Monday](#id-section31)
* [Entry 32: 2020-02-25, Tuesday](#id-section32)
* [Entry 33: 2020-02-26, Wednesday](#id-section33)
* [Entry 34: 2020-02-27, Thursday](#id-section34)
* [Entry 35: 2020-02-28, Friday](#id-section35)
* [Entry 36: 2020-03-02, Monday](#id-section36)
* [Entry 37: 2020-03-03, Tuesday](#id-section37)
* [Entry 38: 2020-03-04, Wednesday](#id-section38)
* [Entry 39: 2020-03-05, Thursday](#id-section39)
* [Entry 40: 2020-03-06, Friday](#id-section40)
* [Entry 41: 2020-03-09, Monday](#id-section41)
* [Entry 42: 2020-03-10, Tuesday](#id-section42)
* [Entry 43: 2020-03-11, Wednesday](#id-section43)
* [Entry 44: 2020-03-12, Thursday](#id-section44)
* [Entry 45: 2020-03-13, Friday](#id-section45)
* [Entry 46: 2020-03-16, Monday](#id-section46)
* [Entry 47: 2020-03-17, Tuesday](#id-section47)
* [Entry 48: 2020-03-18, Wednesday](#id-section48)
* [Entry 49: 2020-03-19, Thursday](#id-section49)
* [Entry 50: 2020-03-20, Friday](#id-section50)
* [Entry 51: 2020-03-23, Monday](#id-section51)
* [Entry 52: 2020-03-24, Tuesday](#id-section52)
* [Entry 53: 2020-03-25, Wednesday](#id-section53)
* [Entry 54: 2020-03-26, Thursday](#id-section54)
* [Entry 55: 2020-03-27, Friday](#id-section55)
* [Entry 56: 2020-03-30, Monday](#id-section56)
* [Entry 57: 2020-03-31, Tuesday](#id-section57)
* [Entry 58: 2020-04-01, Wednesday](#id-section58)
* [Entry 59: 2020-04-02, Thursday](#id-section59)
* [Entry 60: 2020-04-03, Friday](#id-section60)
* [Entry 61: 2020-04-06, Monday](#id-section61)
* [Entry 62: 2020-04-07, Tuesday](#id-section62)
* [Entry 63: 2020-04-08, Wednesday](#id-section63)
* [Entry 64: 2020-04-09, Thursday](#id-section64)
* [Entry 65: 2020-04-10, Friday](#id-section65)
* [Entry 66: 2020-04-13, Monday](#id-section66)
* [Entry 67: 2020-04-14, Tuesday](#id-section67)
* [Entry 68: 2020-04-15, Wednesday](#id-section68)
* [Entry 69: 2020-04-16, Thursday](#id-section69)
* [Entry 70: 2020-04-17, Friday](#id-section70)
* [Entry 71: 2020-04-20, Monday](#id-section71)
* [Entry 72: 2020-04-21, Tuesday](#id-section72)
* [Entry 73: 2020-04-22, Wednesday](#id-section73)
* [Entry 74: 2020-04-23, Thursday](#id-section74)
* [Entry 75: 2020-04-24, Friday](#id-section75)
* [Entry 76: 2020-04-27, Monday](#id-section76)
* [Entry 77: 2020-04-28, Tuesday](#id-section77)
* [Entry 78: 2020-04-29, Wednesday](#id-section78)
* [Entry 79: 2020-04-30, Thursday](#id-section79)
* [Entry 80: 2020-05-01, Friday](#id-section80)
* [Entry 81: 2020-05-04, Monday](#id-section81)
* [Entry 82: 2020-05-05, Tuesday](#id-section82)
* [Entry 83: 2020-05-06, Wednesday](#id-section83)
* [Entry 84: 2020-05-07, Thursday](#id-section84)
* [Entry 85: 2020-05-08, Friday](#id-section85)


------    
<div id='id-section1'/>   


### Entry 1: 2020-01-13, Introductory Class.   

#### Ecological Genomics:
* species interactions @ genomic look. 

* Study of genes with relation to organims interacting with the enviroment.

* Inherently about evolution. 

#### Population Genetics:
* 1920s-1930s

* Sewall Wright and R.A. Fisher

* Mathematical Theory:

1.  A1A2

2. p + q = 1 (allele frequencies adding to 1)

3.  HWE: 1 = p^2 + 2pq + q^2

4. Whright-Fisher population: infinitely large, cloased and unfragmented, random mating, no natural selection

* When N is finite and there are sampling effects, genetic drift occur.

* Island Model: Multiple populations, subdivided but connected through migration.

* Fst= (var(p))/(mean(p)(mean(q)))

#### Selective Sweeps:

* 1970s: allozymes

* 1980s: PCR, microsatelltes, DNA sequences using Sanger's method

#### Molecular Evolution:

* M. Kimura, important architect of moleculat evolution field. 

* Neutral Theory of Molecular Evolution.

* Probability of a new mutation 1/2N = mu and the the prbability of being fixed.

* dN/dS = (Nmutations/Nsites)/(Synonimous mutations/S sites) = w, if: 

1. w >> 1 w>2 there is positive selection

2. w = 1 neutral

3. w << 1 negative or purifying selections
  
* Tajima's D

1. pi = nucleotide diversity

2. S = number of segregating sites

3. Pairwise calculations. 

------    
<div id='id-section2'/>   


### Entry 2: 2020-01-15, First info-update class.   

#### To have in mind!

* Your Questions!

* Study organisms (Is there a reference genome? How big? Diploid, Hapliod, Polyploids?)

* Type of Sample (DNA, RNA, combination?)

* Library: biological library that has not been prepared.

1. Ex: Whole genome sequences, RNA Seq, Exom catcher, GBS, Amplicon Sequencing, Associated methods for epigenomics.

* Sequencing platform: Ilumina for short reads sequencing, Pac Bio and Nano probe for long reads.

#### Info updates about: 

1. Illumina, Long Reads sequences.

2. RNA Seq, GNS, Bisulfite sequencing, Exome Capture Sequencing.

------    
<div id='id-section3'/>   


### Entry 3: 2020-01-22, Second info-updates class.   

### My Info Update Presentation:

* Amplicon: Is a piece of DNA or RNA that is the source and/or product of amplification or replication events.

* In other words, is a segment of genetic material that undergoes simplification and contains replicated genetic material. Depending on what are you working with, amplicons can be direct repeat or inverted repeat, and can be linear or circular in structure. 

* Important: the term amplicon is often used interchangeably with PCR products.

* Amplicon sequences results in high coverage of a specific region, making amplicon sequences useful to detect variants at very low levels and frequencies. Also, it allows for multiplexing of samples.

* Useful for: genome targeting and detection  of hot-spot mutations, gene fusions, SNPs and in disciplines such as bacterial metagenomics or biodiversity assesments. 

### Steps:

1. Sample Selection: Environmental Samples. 

2. DNA or RNA extractions.

3. Library preparation:

3a. First PCR to amplify target genes with primers synthethized with a head sequence at the end.

3b. Optimal purification

3c. Second PCR to amplify products with primers that consist of the head sequence and include at the 5' end a library-specific barcode. 

3d. Purification with magnetic beads and stand.

3e. Once you get an equimlar amount of purified amplicons they are pooled.

4. Sequencing: Miseq Illumina Sequencing.


#### First in class coding:

[First coding tutorial](https://pespenilab.github.io/Ecological-Genomics/Tutorial/2020-01-22_Command_Line_Unix.html)

* Major calls: 

1. pwd : to know where do you live on the server

2. ~/ : same thing as typing /users/j/r/jruizaro

3. cd : change directory

4. mkdir : make directory

5. ll : to look what is inside directory

6. head : to look first rows of a document


------    
<div id='id-section9'/>   


### Entry 4: 2020-01-27, First paper discussion.   

[Temporal genomic contrasts reveal rapid evolutionary responses in an alpine mammal during recent climate change](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1008119)

* Take Home Message: Environmental changes inluences demographic patterns with quantifiable changes to selection and genetic drift. 

### Common Vocabulary

1. Population Genomics: selection and drift across the genome. 

* Drift: demographic - changes in abundance and in distribution, cause by environmental changes.

* Selection: changes in selection.

* In population genomics, linkages and interactions are studied, in population genetics not. 

2. Looking across the genome is challenging cause signals can be undistinguishable. We need to separate and differenctiate the results that demographhic changes and selection leave at the genome.

3. Genomic environment is an environment by itself.

4. Linkage disequilibrium: non-random association of alleles at two or more loci in a general population. 

5. We expect selection to act locality and on a particular site with LD, while we expect drift to act globally (affecting the mean, variance and the diversity).

6. Demographic history: 

* Ne = effective population size, size where a population behave as if it were a W-F population.

* Smaller population size, greater the drift.

* Migration = gene flow among and between populationg.

* Divergence time. 

* Coalescent theory: probability of two random alleles copies sharing a common ancestor or accommon gene in the past.

* 2Ne allele copies in a population of Ne individuals. 

* We need to sample enough to capture the most recent common ancestor,

* If a population is changing in size, that will affect the rate of coalescence appearance. You can use this know understand the behavior of the population (ex: bottleneck, expansion, etc.)

* If Ne split = divergence, first you will see a lot of colescence and back in time it will slow down. 

* In a bottleneck, you will lose many of the rare lineages and retain common ones.

* Site-frequency expectrum.

7. Positive Selection

------    
<div id='id-section10'/>   


### Entry 5: 2020-01-29, Second Tutorial: Working with batch scripts.   

[Second Tutorial](https://pespenilab.github.io/Ecological-Genomics/2020-01-29_PopGenomics_Day1.html)

* Species of Interest: Red spruce. Tree species that has undergoes through latitudinal and elevational migration. Now there are unconnected and fragmentated populations in the top of the appalachians going from New York to South Carolina. 

* In our dataset, we are working with genomic DNA of 110 mother trees from 23 populations. 

#### Pipeline:

1. .fastq.gz, we will visualize them using FastQC.

2. trimmed.fastq, using Trimmomatic.

3. Visualize the post trimming.

4. Map or alignment to the references genome.

5. Map (or align) to the reference genome using bwa. File: .sam.

6. post.processing using samtools and sambamba. Making a binary file: .bam.

7. remove drops, stats

[Second Tutorial](https://pespenilab.github.io/Ecological-Genomics/2020-01-29_PopGenomics_Day1.html) 

* Because files inside RS_ExomeSeq are .gz, to see the individual file we can no use head.We use zcat instead, to see it without uncomprresing it: (zcat NAME) | head -n 4. 

* We will see the barcodes indexes (pair) with a four line with a quality encoding score called the Q score. 

* Phred Quality Score: 10 or < 90 % accuracy 20 or > more than 99% accuracy: example p=10^(-38/10)= prob(of the machine misscalling the nucleotide on the loci) = 0.0038.

#### Population assigned to me: WA. 

#### Step:

1. vim in myscripts

2. press i

3. #!/bin/bash

4. cd ~/Ecological_Genomics_2020/myresults/ 

5. mkdir fastqc

6. for file /data/project_data/RS_ExomeSeq/fastq/edge_fastq/WA*fastq.gz

6.5. do

7. Output file in /fastqc: fastqc ${file} -o fastqc/

8. Closing the loop: done

9. Exit editing mode: ESC, shift :, wq fastqc.sh

* To move files aroud: mv filename dir/ 

10. permision: -rw-r--r-- without x means file is not executable, then chmod u+x fastqc.sh.

11. bash fastqc.sh

12. Push everything and pull it bacj to your local repository.

#### Now, we are going to trim.

1. Using Trimmomatic.

2. Download from data/scripts and save it into my scripts: cp trim_loop.sh ~/REPOSITORY/myscripts/

3. Open it in vi (filename) nad edit your population name.

4. bash trim_loop.sh


------    
<div id='id-section11'/>   


### Entry 6: 2020-02-03, Second Paper Dicsussion   

### Info-updated

### Genomic diversity - How to calculated and what it does it say?

* Effective population size = population size of an ideal population that follows W-F assumptions.

* Factors deviating Ne from N: 

1. Non-random mating

2. Selection

3. Reproductive Skew 

4. Non-constant population size

5. Unequal sex ratio (Segwall Wright) <= Ne = (4Nm x Nf)/(Nm + Nf)

6. Can be estimated by previous formulas, but there will be other variables (ex. mutations, migration, etc.) which will end up affecting Ne.

7. nucleotide diversity (or pi) = 4(Ne or net probability difference in nucleotide) u (or mutation rate with units of changes per site per generation)

* Nei's genetic distance - measurement of diversity

* Fst (population structure) = 1/(pi + 1) (as pi increases Fst decreases, menas population is more homogenous)

* or Fst = 1 - (Hs (or average H of subpop.)/Ht (or average H for whole pop.))

* Heterozygozity (H): condition of having two different alleles at a locus.

* Site Frequency Spectrum: distribution of the allele frequencies of a given set of loci (often SNPs) in a population or sample. 

* Tajima's D: statistic that compares the average number of pairwise differences with the number of segregating sites. If = 0, in equilibrium, factors are not influencing too much. < 0 (expansion, we will have more rare alleles or more rare mutations appearing) or > 0 (contraction).  

### Paper Discussion (Evolution of sociality in spiders leads to depleted genomic diversity at both population and species level)

Take Home Message: How the transition to sociology can affect Ne? Non-random mating, Reproductive Skew, Unequal sex ratio.

* Fst = 1 - (average pi of subpopulation/ total species pi)

* lower K = more geneflow

* Inbreeding coefficient: how much inbreeding is happening.

* Migration push TMRCA further back in the past. 

* Social = total pi = 0.00056, Ne = 21 x 10^3

* Subsocial = total pi = 0.00474, Ne = 178 x 10^3

* mutation rate = 6.65 x 10^-9


------    
<div id='id-section18'/>   


### Entry 7: 2020-02-05, Third Tutorial   

[Third Tutorial](https://pespenilab.github.io/Ecological-Genomics/2020-02-05_PopGenomics_Day2.html)

#### Mapping cleaned and trimmed reads against the reference genome

[congenie](http://congenie.org/) to look for availability of reference genomes.

* wget -> to get genomes from the internet

* We are going to use a subsetted of the reference genome to include just the contigs that contain one or more probes from our exon capture experiment. 

* Average size of contigs <- 10.5 kbp.

* The N50 of the reduced reference is 101,375 bp (that particular contigs + biggers give of 50%). N50 take 50% of 668 Mb, and start from the biggest contigs moving back until we get 334 MB (N50 is the smallest contigs in which the sum of all larger contigs give of 50% of our total genome).

#### Wrapper

* mapping - aligment to reference genome

* bwa program: algorithm for mapping reads to references

* bwa mem -t 1 -M ${ref} ${forward} ${reverse} > ${output}/BWA/${name}.sam

* CTRL-A + Ctrl-D to let it running on the background

* screen -r to recover the screen 

------    
<div id='id-section19'/>   


### Entry 8: 2020-02-10, Third Paper Discussion.   

### Info-updated

### GWAs (Genome Wide Association Studies)/ WGWAs (Whole)

* Genotype to phenotype retrospective studies.

* 2002 First WGWAs analysis performed : Microbial insfrection. 

* 3000 studies has been don't up to the year 2017.

* In medical studies: rare variants mapped to SNPs in the genome (Ex. diabetes, parkinson, etc.).

* Which SNPs are the most responsible to cause the genetic deseases. (With case control, simple comparison to see what genetic variants have the effect).

* Manhattan plot: SNPs are plot across the whole genome and we can statistically see which one show significant differences.

* Methodology for classic GWAs:

1. Making/finding population that differ in a singular trait

2. Using MAseq to generate data of genomic variance

3. Making statistical inferences

We end up finding:

1. Causal impact of the genetic variance: great.

2. Close to causal to genetic variance: good.

3. bias -> population bias: horrible. 

Problems with GWAs:

1. SNPs are not genes.

2. Low heritability of traits - distinctions can become unclear.

3. Ancestral association - problems in populations with smaller population sizes due to violation of WF assumptions. There is less recombination. We address this issue by fitting the data (to look for cofounding variables and taking out the variability created by the variable we are not looking into).

QQplots:

1. lambda: median empirically observed variation/median expected vaiation = 1 (good)

2. If lambda is bigger than 1, ecologist devide their lambda to the expected lambda and that decrease variability of the data.

Ecological source of errors:

1. Different methodology from human analysis.

2. Correlated traits: joint GWAs analyses. (PCA (represents genome wide ancestor) and genome control).

3. Trait-structure extrapolation. Causal association between SNPs and phenotypic traits, is difficult to study when effecive size and allele frequency are very high.

4. Significant treshold. Competition between acuraccy and broadness. 

------    
<div id='id-section20'/>   

### Entry 22: 2020-02-11, Tuesday.   

[Tutorial](https://pespenilab.github.io/Ecological-Genomics/2020-02-12_PopGenomics_Day3.html)

Codes:

head WA_419.sam to see first lines of the file

tail WA_419.sam to see bottom of the file

[SAM FLAG DECODER](https://broadinstitute.github.io/picard/explain-flags.html): 147 (it means that the read was paired, mapped in proper pair, read reverse strand, second in pair)

In this "Decoder" we are looking to avoid not primarly alignment, if it fails quality control checks, etc.

Mapping quality score: higher the number, the better.

samtools flagstat give us basic information about pur files

*Ex: Total number of reads, number of reads paired in sequencing, etc.

To get that information for all of your files: 

All should have the extention: filename sorted.rmdup.bam and .bai.

Mine is rmup instead or rmdup.

Depth - The more reads you have, the more confidence you are going to be about the info you ae generating. Compared to reference genome.

To see mapping of a single individual:

samtools tview /data/project_data/RS_ExomeSeq/mapping/BWA/WA_419.sorted.rmup.bam /data/project_data/RS_ExomeSeq/ReferenceGenomes/Pabies1.0-genome_reduced.fa

Genotype likelihood: prob of observing sequenced data ...

Chenck in he ANGSD  with ll -rt to see if files are over there.

------    
<div id='id-section21'/>   


### Entry 10: 2020-02-19, Fifth Tutorial.   

[Fifth Tutorial](https://pespenilab.github.io/Ecological-Genomics/2020-02-12_PopGenomics_Day4.html)

We are going to do folding to our site frequency expectrum. Folding the plot and moving all of the 2N high frequencies alleles to the beginning. This is because we don't know with allele is pur ancestor. 
Folded spectra: plotting the frequencies with the minor allele frequencies. 

Today we are going to:

1. Estimating (rough) SFS

2. .sfs

3. Estimate SFS using .sfs as a prior

4. doTheta (Parameter of population that describe diversity = 4Neu)

5. thetha_stats

R codes to generate stats: We obtained positive Tajima's D which means that a bottleneck occured before fragmentation.

```
# Setting Working Directory
setwd("C:/Users/jorge/Desktop/F-UVM - Grad/Third Year - Second Semester - UVM/Ecological Genomics/Stats")

list.files()

# Updloading Data

SFS <- scan("WA_outFold.sfs") # Estimates of frequence of alleles.
SFS

sumSFS <- sum(SFS)
sumSFS # How meany sites did we match

pctPoly <-  (1-(SFS[1]/sumSFS))*100
pctPoly

plotSFS <- SFS[-c(1,length(SFS))]
barplot(plotSFS)


list.files()

div <- read.table("WA_folded_allsites.thetas.idx.pestPG")

colnames(div) <- c("window","chrname", "wincenter", "tW", "tP", "tF", "tH", "tL",
                   "tajD", "fulif", "fuliD", "fayH", "zengsE", "numSites")
head(div)
div$tWpersite <- div$tW/div$numSites
div$tPpersite <- div$tP/div$numSites
str(div)

pdf("WA_diversity_stats.pdf")
par(mfrow=c(2,2))
hist(div$tWpersite, col="gray", xlab="Theta-W", main="")
hist(div$tPpersite, col="gray", xlab="Theta-Pi", main="")
hist(div$tajD, col="gray", xlab="Tajima's D", main="")
barplot(plotSFS)
dev.off()

summary(div)
```

------    
<div id='id-section22'/>   


### Entry 11: 2020-02-24, Fourth Paper Discussion.

Ecological Genomics: Intersection between population genetics, molecular evolution and ecology (biotic and abiotic enviroment).

Example: p*q, Coalescence theory, Nucleotide diversity, Tajima's D, SFS. Plus a ton of NGS.

Trancriptomics: Measuring genes expression when you hold/control enviromental conditions constant. To reveal genetically-control diiferences phenotypes at the molecular level. 

What is a phenotype? 
* Characteristics of an organism that can be observed. (eg. coat color (morphological scale), disease resistance/susceptibility (celular and molecular level)).

Central Dogma of Molecular Biology: DNA (transcription) ---> RNA (translation) ---> Protein ---> Phenotype

Transcriptomics act on the RNA section of our Dogma. 

Reverse ecology: to indicate the phenotype natural selection is acting on.

Examples: 

1. Mutations in coding/DNA that affects AA

2. Splice site variation

3. Promoter and enhancers affecting expression level and timing of expression, or cell/tissue type in which the genome expressed. Also, conditions of expression

4. Post-translational modifications (-P), at the protein level

5. Epigenetic modifications (can affect all of the above)

Transcriptomics give you an active vision of what it is hapening at a certain time. It is global/unbiased. And it is cheap (Illumina) and you can assembly a new (de novo) transcriptome.

Phenotype = G + E + (G x E). You can control environemnt and/or experimentally induce phenotype of interest. 

Molecular underpinnings of a phenotype. 

Factors to consider (Take into consideration your questions and hypotheses, they will affect factors): 

1. Common gardens - controlling enviromental conditions. 

2. Treatments/conditions - related to phenotype of interest. 

3. Populations

4. Tissue, cell

5. Life history

6. Transgenerational environment

7. Sex of organism and reproductive stage

Work flow:

1. Careful experimental design, considering our questions, hypotheses and factors

2. Experiment and sample tissues*individuals, save RNA - labile. Extract, prep, sequence (mRNA, 3'tag, other sequencing techniques)

3. Process + Analyze sequence data. Quality check -> Clean -> Qc (Working with .fastq). Map to reference + Extract count data. Normalize the variation among your samples. Count data matrix. 

4. Integrate: GO, Network analyzes, SNP, Tajima's D, microbiome data. 

Article: [Strong phenotypic plasticity limits potential for evolutionary responses to climate change](https://www.nature.com/articles/s41467-018-03384-9)


------    
<div id='id-section23'/>   


### Entry 12: 2020-02-26, Transcriptomics First Session.   
[Tutorial](https://pespenilab.github.io/Ecological-Genomics/2020-02-26_RNA-seq_Day1.html)

Goal: To assess the gene expression responses of Red spruce individuals from these habitats in response to experimental treatments of heat and heat+drought.

With the library prep and sequencing used, little RNA with good quality is enough to work. 

Possible questions to ask with this data set:
Factors:

1. Treatment: C, H, D

2. Source Climate: 2, HotDry and CoolWet

3. Time: 0, 5, 10

1) Do individuals from different climate sources have different gene expression:

* in each condition? ex ~ SC + trt

* at different time points? ex ~ time + source climate + (time*SC) + family 

* interactions ex ~ SC +trt + (SC*trt)

#### My sample will be: KAN D and KAN H 

------    
<div id='id-section24'/>   


### Entry 13: 2020-03-02, Fifth Paper Discussion.   

Info-Update: 

Differential Gene Expression: Difference in transcript abundance between experimental groups or populations. We are looking at specific genes that are changing (more than you will expect by chance). 

Useful in studyng how genotype influence phenotypes. We can conduct experiment to see P = E x G x (GxE), control for environmental conditions. 

How to conduct an experiment? 

1. Sample Prep

2. RNA extraction

3. Library Preparation

4. Sequencing 

5. Bionformatic (Quality control (FastQC and trimming), Mapping and counting (Salmon))

Normalization Section:

We have a data matrix/gene count table. We would have gene number in each row and samples in each columns. The data will be in "counts". Normalization address two problems: 

1. Depth: Library size.

2. Library composition: Some genes can take a lot of the depth and you have to normalize. 

Normalization Methods: 

1. Counts per million (CPM) - sequencing depth. 

2. Transcripts per kilobase million. (Depth and gene length)

3. Fragments per kilobase million. (Depth and gene length)

4. edge R - depth, gene size and library composition. 

5. DESeq2 - depth composition. Provides and sclling factor to divide each gene by it.

Differential Expression: 

20,000 x 0.05 (p-val) = 1,000 false positive.

Independent Filtering: limiting the number of test based on a cut off, baseMean. 

Benjamini Hochberg (BH): Adjusted p-value to control false positives. FDR - False discovery rate.

Generalized Linear Model (GLM): Neative binomial distribution. Wald test: p-value.

Statistical Models. Ex: exp~time + source climate + (SC X time), we are asking how well do these variables predict expression level.

Visualization:

Sequencing Summary Statistics. Ex: Total read counts by sample, or Number of null genes by sample. Or heat map, how much each gene in each sample is changing relative to the control. 

Enrichment Analysis: 

Functional database:

1. Gene Ontology (GO)

* Molecular Function: adenylate cclase activiting

* Biological Process: puridimine.

* Cell Compartment: cibosome.

2. KEGG pathway

*Gentic Info Proc (ex. tanscription)

Methods: Over Representation Analysis. 

Gene Set Enrichment Analysis (rank based methods). 

Article: [Insights into high-pressure acclimation:
comparative transcriptome analysis of sea
cucumber Apostichopus japonicus at
different hydrostatic pressure exposures](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-020-6480-9)

------    
<div id='id-section25'/>   


### Entry 14: 2020-03-04, Transcriptomics Day Two.   

```
library(tximportData)
library(tximport)
library(DESeq2)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(ggpubr)
library(readr)
```

[Transcriptomics Day Two](https://pespenilab.github.io/Ecological-Genomics/2020-03-044_RNA-seq_Day2.html)

Mapping rates in the initialmapping repository: Percent of the reads in files that mapped back to the transcriptome.

```
library(tximportData)
library(tximport)

#locate the directory containing the files. 
dir <- "/data/project_data/RS_RNASeq/salmon/allmapping" #defining our directory
list.files(dir) 

# read in table with sample ids
samples <- read.table("/data/project_data/RS_RNASeq/salmon/RS_samples.txt", header=TRUE) 

# now point to quant files
all_files <- file.path(dir, samples$sample, "quant.sf") #lining up samples
names(all_files) <- samples$sample 

# what would be used if linked transcripts to genes
#txi <- tximport(files, type = "salmon", tx2gene = tx2gene)
# to be able to run without tx2gene
txi <- tximport(all_files, type = "salmon", txOut=TRUE)  
names(txi)

head(txi$counts)

countsMatrix <- txi$counts
dim(countsMatrix)
#[1] 66069    76

# To write out
write.table(countsMatrix, file = "RS_countsMatrix.txt", col.names = T, row.names = T, quote = F) 
```

------    
<div id='id-section26'/>   


### Entry 15: 2020-03-18, Transcriptomic Day Three

[Transcriptomic Day Three](https://pespenilab.github.io/Ecological-Genomics/2020-03-17_RNA-seq_Day3.html)

Recall that two weeks ago you all wrote for loops to map your set of cleaned fastq files to the reference transcriptome. We discovered that we had low mapping rates, ~2%! We did some troubleshooting in class. We further hypothesized that many of our reads were not mapping because the reference we had selected included only the coding region. In working with 3’ RNAseq data, much of our sequencing effort is likely to be in the 3’ UTR (untranslated region). We concatenated the reference sequences for the coding (“cds”) and the 3’ UTR (“2kb downstream”) for each gene. We then mapped to this new reference using salmon (as you had done before). Our mapping rate improved dramatically, ranging from 40-70% of reads mapping across samples, mean of 52%.

* We are working with: 66408 transcripts that we are mapping by 76 samples. 66408 is the number of reference transcripts.

* In the matrix data table for each of our sample we have the amount of reads that mapped to the trancripts.

* Few data (reads) will cause difficulty in detect signals or differential expession. But it will depend on our interest in detecting differential expression in transcripts be expressed in lower levels. But, 3-5 million reads is a good rules of thumbs. 

* You can ask the sequencing agency to sequence it again for you to get more reads. 

* If your mapping to a difference species, then that can decrease the percentage of mapping. 

```
## Set your working directory
setwd("C:/Users/jorge/Desktop/F-UVM - Grad/Third Year - Second Semester - UVM/Ecological Genomics/Stats/RS_counts_samples")

## Import the libraries that we're likely to need in this session
library(DESeq2)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(ggpubr)
library(wesanderson)
library(vsn)  ### First: BiocManager::install("vsn") AND BiocManager::install("hexbin")

## Import the counts matrix
countsTable <- read.table("RS_cds2kb_countsMatrix.txt", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # Need to round because DESeq wants only integers
head(countsTableRound)

## Import the samples description table - links each sample to factors of the experimental design.
# Need the colClasses otherwise imports "day" as numeric which DESeq doesn't like, coula altneratively change to d0, d5, d10
conds <- read.delim("RS_samples.txt", header=TRUE, stringsAsFactors = TRUE, row.names=1, colClasses=c('factor', 'factor', 'factor', 'factor'))
head(conds)
dim(conds)

############ Try with only Day 10 data



# grep("10", names(countsTableRound), value = TRUE)
# day10countstable <- subset(countsTableRound, grep("10", names(countsTableRound), value = TRUE)) #doesn't work has to be logical



day10countstable <- countsTableRound %>% select(contains("10"))
dim(day10countstable)



conds10<- subset(conds, day=="10")
dim(conds10)
head(conds10)

############

## Let's see how many reads we have from each sample:
colSums(countsTableRound) #Sum up all the reads from each colums
mean(colSums(countsTableRound))
barplot(colSums(countsTableRound), las=3, cex.names=0.5,names.arg = substring(colnames(countsTableRound),1,13))
abline(h=mean(colSums(countsTableRound)), col="blue", lwd =2)

# What's the average number of counts per gene
rowSums(countsTableRound)
mean(rowSums(countsTable))
median(rowSums(countsTable)) # Gene expression does not follow a normal distribution
# Wow, this is showing dispersion across genes - differences in magnitude of expression

# What's the average number of counts per gene per sample
apply(countsTableRound,2,mean)

## Create a DESeq object and define the experimental design here with the tilde
dds <- DESeqDataSetFromMatrix(countData = countsTableRound, 
                              colData = conds, 
                              design = ~ climate + day + treatment) 
#DESeq does not like redundancing, you need to export unique and independent factors.
#Above we use counts matrix, condition and experimental design.

dim(dds) # 66408, 76

# Filter out genes with few reads

dds <- dds [rowSums(counts(dds)) > 76]
dim(dds) # 23887, 76 This is filtering to sum of 76 reads across all samples
# 7884, 76 Filtering to sum of 760 reads across all samples.

## Run the DESeq model to test for differential gene expression: 
#1) estimate size factors (per sample), 
#2) estimate dispersion (per gene), 
#3) run negative binomial glm

dds <- DESeq(dds)

# List the results you've generated

resultsNames(dds)

# [1] "Intercept"            "pop_BRU_05_vs_ASC_06"
# [3] "pop_CAM_02_vs_ASC_06" "pop_ESC_01_vs_ASC_06"
# [5] "pop_JAY_02_vs_ASC_06" "pop_KAN_04_vs_ASC_06"
# [7] "pop_LOL_02_vs_ASC_06" "pop_MMF_13_vs_ASC_06"
# [9] "pop_NOR_02_vs_ASC_06" "pop_XBM_07_vs_ASC_06"
# [11] "day_10_vs_0"          "day_5_vs_0"          
# [13] "treatment_D_vs_C"     "treatment_H_vs_C"  

# Running the model: design = ~ climate + day + treatment
# [1] "Intercept"        "climate_HD_vs_CW" "day_10_vs_0"     
# [4] "day_5_vs_0"       "treatment_D_vs_C" "treatment_H_vs_C"

# Order and list and summarize results from specific contrasts
# Here you set your adjusted p-value cutoff, can make summary tables of the number of genes differentially expressed (up- or down-regulated) for each contrast
res <- results(dds, alpha = 0.05) 
res <- res[order(res$padj),]
head(res) #Order atter positive logfold is in H and negatives are higher in C.

# log2 fold change (MLE): treatment H vs C 
# Wald test p-value: treatment H vs C 
# DataFrame with 6 rows and 6 columns
# baseMean    log2FoldChange
# <numeric>         <numeric>
#   MA_172878g0010   15.8548874481417  2.26882089354203
# MA_28973g0010    18.8813749792546 -1.96674876177405
# MA_10426002g0010 10.8980752578363 -1.20788022518503
# MA_10426033g0010 67.6992372010061 0.738031525498394
# MA_10429525g0010 60.5937645508928  1.17169400658399
# MA_10433965g0010 49.9866944326994 0.612163878272307
# lfcSE             stat
# <numeric>        <numeric>
#   MA_172878g0010   0.441981248080773 5.13329672558279
# MA_28973g0010    0.413191368286972 -4.7598979860782
# MA_10426002g0010 0.283872734887581 -4.2550061233016
# MA_10426033g0010 0.180021281847179 4.09969042507382
# MA_10429525g0010 0.279889684265675 4.18627077899663
# MA_10433965g0010 0.150494357995378 4.06768656597152
# pvalue                padj
# <numeric>           <numeric>
#   MA_172878g0010   2.84710503526532e-07 0.00210030938451523
# MA_28973g0010     1.9369083372221e-06 0.00714428640184372
# MA_10426002g0010 2.09043294338703e-05  0.0291896759160226
# MA_10426033g0010 4.13703152545171e-05  0.0291896759160226
# MA_10429525g0010 2.83575028580428e-05  0.0291896759160226
# MA_10433965g0010 4.74821893713259e-05  0.0291896759160226

summary(res)

# out of 53066 with nonzero total read count
# adjusted p-value < 0.05
# LFC > 0 (up)       : 15, 0.028%
# LFC < 0 (down)     : 6, 0.011%
# outliers [1]       : 308, 0.58%
# low counts [2]     : 45381, 86%
# (mean count < 8)
# [1] see 'cooksCutoff' argument of ?results
# [2] see 'independentFiltering' argument of ?results

res_treatCD <- results(dds, name = "treatment_D_vs_C", alpha=0.05)
res_treatCD <- res_treatCD[order(res_treatCD$padj),]
head(res_treatCD)

# log2 fold change (MLE): treatment D vs C 
# Wald test p-value: treatment D vs C 
# DataFrame with 6 rows and 6 columns
# baseMean   log2FoldChange
# <numeric>        <numeric>
#   MA_10257300g0010 20.9979917001674  6.3160877571623
# MA_444738g0020   23.5872071084088 2.60475479951658
# MA_57964g0010    7.89927388331396 5.39739873586083
# MA_75192g0010    37.9183573851468 5.81210235837303
# MA_10428616g0010  35.758883777048 3.82582767481363
# MA_7017g0010     64.7924705055064 2.64414218710183
# lfcSE             stat
# <numeric>        <numeric>
#   MA_10257300g0010 0.761778438070059 8.29123986911983
# MA_444738g0020   0.330944830911612 7.87066168201386
# MA_57964g0010    0.694994697724825 7.76610059548665
# MA_75192g0010    0.768762098604425 7.56033936756775
# MA_10428616g0010   0.5105334668651 7.49378429254776
# MA_7017g0010     0.358927431461694 7.36678769949079
# pvalue                 padj
# <numeric>            <numeric>
#   MA_10257300g0010 1.12074011571854e-16 1.74095769575717e-12
# MA_444738g0020   3.52770431249488e-15 2.73996793951477e-11
# MA_57964g0010    8.09392779865987e-15 4.19103581414608e-11
# MA_75192g0010    4.02019076294704e-14 1.56124108279048e-10
# MA_10428616g0010 6.69156646447418e-14 2.07893586918284e-10
# MA_7017g0010     1.74788498523952e-13 4.52527422678512e-10

summary(res_treatCD)

# out of 23887 with nonzero total read count
# adjusted p-value < 0.05
# LFC > 0 (up)       : 671, 2.8%
# LFC < 0 (down)     : 427, 1.8%
# outliers [1]       : 62, 0.26%
# low counts [2]     : 8291, 35%
# (mean count < 2)
# [1] see 'cooksCutoff' argument of ?results
# [2] see 'independentFiltering' argument of ?results

##### Data visualization #####

# MA plot
plotMA(res_treatCD,ylim=c(-3,3)) #On top expressed more in H vr C, below the line is the opposite. Red means they are significant expreseed and greater logfold change.


# PCA
vsd <- vst(dds, blind = FALSE)

data <- plotPCA(vsd,intgroup=c("climate","treatment","day"), returnData=TRUE)
percentVar <- round(100 * attr(data,"percentVar"))

data$treatment <- factor(data$treatment, levels=c("C","H","D"), labels = c("C","H","D"))
data$day <- factor(data$day, levels=c("0","5","10"), labels = c("0","5","10"))

ggplot(data, aes(PC1, PC2, color=day, shape=treatment)) +
  geom_point(size=4, alpha=0.85) +
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) +
  theme_minimal()

# Counts of specific top gene! (important validatition that the normalization, model is working)
d <-plotCounts(dds, gene="MA_75192g0010", intgroup = (c("treatment","climate","day")), returnData=TRUE)
d 


p <-ggplot(d, aes(x=treatment, y=count, colour=day, shape=climate)) + 
  theme_minimal() + theme(text = element_text(size=20), panel.grid.major=element_line(colour="grey"))
p <- p + geom_point(position=position_jitter(w=0.3,h=0), size=3) +
  scale_x_discrete(limits=c("C","H","D"))
p

# Heatmap of top 20 genes sorted by pvalue

library(pheatmap)
topgenes <- head(rownames(res_treatCD),20)
mat <- assay(vsd)[topgenes,]
mat <- mat - rowMeans(mat)
df <- as.data.frame(colData(dds)[,c("treatment","climate","day")])
pheatmap(mat, annotation_col=df)
```

```
#Using only day 10
## Set your working directory
setwd("C:/Users/jorge/Desktop/F-UVM - Grad/Third Year - Second Semester - UVM/Ecological Genomics/Stats/RS_counts_samples")

## Import the libraries that we're likely to need in this session
library(DESeq2)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(ggpubr)
library(wesanderson)
library(vsn)  ### First: BiocManager::install("vsn") AND BiocManager::install("hexbin")

## Import the counts matrix
countsTable <- read.table("RS_cds2kb_countsMatrix.txt", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # Need to round because DESeq wants only integers
head(countsTableRound)

## Import the samples description table - links each sample to factors of the experimental design.
# Need the colClasses otherwise imports "day" as numeric which DESeq doesn't like, coula altneratively change to d0, d5, d10
conds <- read.delim("RS_samples.txt", header=TRUE, stringsAsFactors = TRUE, row.names=1, colClasses=c('factor', 'factor', 'factor', 'factor'))
head(conds)
dim(conds)

############ Try with only Day 10 data



# grep("10", names(countsTableRound), value = TRUE)
# day10countstable <- subset(countsTableRound, grep("10", names(countsTableRound), value = TRUE)) #doesn't work has to be logical



day10countstable <- countsTableRound %>% select(contains("10"))
dim(day10countstable)



conds10<- subset(conds, day=="10")
dim(conds10)
head(conds10)

############

## Let's see how many reads we have from each sample:
colSums(day10countstable) #Sum up all the reads from each colums
mean(colSums(day10countstable))
barplot(colSums(day10countstable), las=3, cex.names=0.5,names.arg = substring(colnames(day10countstable),1,13))
abline(h=mean(colSums(day10countstable)), col="blue", lwd =2)

# What's the average number of counts per gene
rowSums(countsTableRound)
mean(rowSums(countsTable))
median(rowSums(countsTable)) # Gene expression does not follow a normal distribution
# Wow, this is showing dispersion across genes - differences in magnitude of expression

# What's the average number of counts per gene per sample
apply(countsTableRound,2,mean)

## Create a DESeq object and define the experimental design here with the tilde
dds <- DESeqDataSetFromMatrix(countData = day10countstable, 
                              colData = conds10, 
                              design = ~ climate + treatment + climate:treatment) 
#DESeq does not like redundancing, you need to export unique and independent factors.
#Above we use counts matrix, condition and experimental design.

dim(dds) # 66408, 30

# Filter out genes with few reads

dds <- dds [rowSums(counts(dds)) > 30]
dim(dds) # 24300, 30 This is filtering to sum of 76 reads across all samples

## Run the DESeq model to test for differential gene expression: 
#1) estimate size factors (per sample), 
#2) estimate dispersion (per gene), 
#3) run negative binomial glm

dds <- DESeq(dds)

# List the results you've generated

resultsNames(dds)

# [1] "Intercept"            "climate_HD_vs_CW"    
# [3] "treatment_D_vs_C"     "treatment_H_vs_C"    
# [5] "climateHD.treatmentD" "climateHD.treatmentH"

res_treatment_D_vs_C <- results(dds, name = "treatment_D_vs_C", alpha=0.05)
res_treatment_D_vs_C <- res_treatment_D_vs_C[order(res_treatment_D_vs_C$padj),]
head(res_treatment_D_vs_C)

# log2 fold change (MLE): treatment D vs C 
# Wald test p-value: treatment D vs C 
# DataFrame with 6 rows and 6 columns
# baseMean    log2FoldChange             lfcSE              stat
# <numeric>         <numeric>         <numeric>         <numeric>
#   MA_10426407g0030 219.715584286121  2.55696344469482 0.324906793273337  7.86983681976665
# MA_75192g0010    77.5190010889928  8.04619662596281  1.17408907419792  6.85313985351545
# MA_10425837g0010 293.426521892966 -3.17899129382686 0.462410078365211 -6.87483132951115
# MA_824288g0010   154.710951677063 -4.15994435220765 0.610952834706399 -6.80894516874901
# MA_133272g0010   9.82528137178526 -6.86599490523253  1.03504041639281 -6.63355246470566
# MA_71201g0010    16.1438828561619 -7.29150111298197   1.1007571709411 -6.62407777616205
# pvalue                 padj
# <numeric>            <numeric>
#   MA_10426407g0030 3.55104122313316e-15 4.77579534099179e-11
# MA_75192g0010    7.22463913264591e-12 3.23880572316516e-08
# MA_10425837g0010 6.20632480288557e-12 3.23880572316516e-08
# MA_824288g0010   9.83169393331549e-12   3.305661292729e-08
# MA_133272g0010   3.27702420845957e-11 7.83231116913848e-08
# MA_71201g0010    3.49422760166785e-11 7.83231116913848e-08

summary(res_treatment_D_vs_C)

# out of 24300 with nonzero total read count
# adjusted p-value < 0.05
# LFC > 0 (up)       : 257, 1.1%
# LFC < 0 (down)     : 327, 1.3%
# outliers [1]       : 121, 0.5%
# low counts [2]     : 10730, 44%
# (mean count < 3)
# [1] see 'cooksCutoff' argument of ?results
# [2] see 'independentFiltering' argument of ?results
```

------    
<div id='id-section27'/>   


### Entry 16: 2020-02-03, Sixth Paper Discussion.   

Integrating biological data and studying their interactions: 

Types of data:

* Gene expression: 

1) counts(normalized by length, etc.)

2) quantitative traits

* Sequence data: 

1) Fatqc, SNPs, QTL

2) pi, AMOVA 

* Environmental data:

1) Stress exposure, temperature gradient

2) Discrete, continous or well-ordered environemntal data.

* Gene copy numbers (GNVs):

1) Form of duplication/deletion

2) Alignment depth

3) Relative to a reference genome

4) Common to remove short CNVs, overly represented CNVs

* Functional enrichment (GO):

1) Associating genes with hierarchical functions.

* Chromatin state:

1) accessible/not accessible, specific histone modifications. 

What types of interactions are we interested in exploring?

1) Expression counts x discrete factors (environment, chromatin state)

2) P = G x E x ......

3) Chromatin state influences transcroptomes access, influences expression.

4) Requires observations for each contribution of levels. 

* Expression versus continouos factors (pops. diversity, environmental gradient):

1) Requires acceptance of a model for 'missing' observations. Scatteplot exp vs "G".

* Expression versul physical space:

1) Approach from spatial stats. var(P) versus distance. 

* Expression vs GO terms:

1) Useful for detecting unde/overrepresented genes. 

2) Helps detanling causal relationships in DE data. 

* Gene-phenotpe mapping: 

1) change gene/set of genes causes change in trait

2) QTL: Trait mapping.

3) GRN directed edges as DE in trget mode.

4) Genotype networks

Analysis: 

1) Expression versus discrete factors. (Reaction graphs)

2) Two-way ANOVA: cont ~ 2+ discrete factors + interactions.

3) Yijk = intercept + ind. effect of factor j + ind. effect of factor i + non-additive effects + error ~N(o,G).

4) AMOVA (Analysis of Molecular Variant). Y = allele frequencies. You are partinianing variance in allele frequences by your difference factors. 

5) ANCOVA: is a blend of analysis of variance (ANOVA) and regression. It is similar to factorial ANOVA, in that it can tell you what additional information you can get by considering one independent variable (factor) at a time, without the influence of the others. 

* Expression vs continiouos:

1) First thin we might try is correlation (p)

2) linear regression/hiher order regression

3) Canalization (Exp levels vs a continous gradient (environment/gene space)). We expect a sudden jump in expression level as we move. 

4) Higher dimension exp. perturbations in reation norm space. (Gene versus Expression (heatmap to observe changes)).

* Geno-Pheno mapping

1) Modularity 

2) Pleitropic effect within modules. 

3) Independence between trait sets/modules. 

Paper: 

[Genome-Wide Genotype-Expression Relationships Reveal
Both Copy Number and Single Nucleotide Differentiation
Contribute to Differential Gene Expression between
Stickleback Ecotypes](https://www.ncbi.nlm.nih.gov/pubmed/31298693)

Parallel divergence: When we have different populations adapting to the same environemnt (even in different locations) the same variants often get selected. 

------    
<div id='id-section17'/>   


### Entry 17: 2020-02-04, First Epigenomic Section.   

Info Update: 

Changes to gene expression that are not due changes in DNA sequence. Anything that influence the transcriptional potential of a cell. 

Genetic variation directly influence epigenetic variation. Ex. Some organisms can not metalated. 

Persistance under environmental change: accimation, adaptation. 

Mechanisms of epigenetics: 

1) Phosphorylation

2) non-coding RNAs (microRNAs)

3) small interfering RNAs

4) Histone modifications

5) DNA methylation (easier to quantified and important in other mechanisms)

Functional consequences of methylation:

1) Promoters/enhancers: 

a) High methylation = repression of expression. 

b) Inhibits binding of TFs.

c) Chromatin structure

2) Intergenic:

a) Silence TEs, etc.

3) Gene Body (Intron/Exon)

Plants show a consistent higher CHG methylation.

Bisulfite sequencing (allow us to measure levels of methylation): forcing the creation of uracile, unable to happen if there is methylation.

Epigenomic data:

Working with copepods. Highly plastics. 

------    
<div id='id-section1000'/>   


### Entry 18: 2020-03-30, Seventh Paper Discussion.   


------    
<div id='id-section30'/>   


### Entry 19: 2020-04-01, Second Epigenomic Section.   

library(methylKit)
library(tidyverse)
library(ggplot2)
library(pheatmap)

# first, we want to read in the raw methylation calls with methylkit

dir <- "/Users/jorge/Desktop/Copepods"

# set directory with absolute path (why is this necessary? I have no idea, but gz files wont work with relative paths)

# read in the sample ids

samples <- read.table("~/data/users/j/r/jruizaro/largefiles/Copepods/sample_id.txt", header=FALSE)


samples <- read.table('sample_id.txt')

# now point to coverage files

files <- file.path(dir, samples$V1)
all(file.exists(files))

# convert to list

file.list <- as.list(files)

# get the names only for naming our samples

nmlist <- as.list(gsub("_1_bismark_bt2_pe.bismark.cov.gz","",samples$V1))

# use methRead to read in the coverage files
myobj <- methRead(location= file.list,
        sample.id =   nmlist,
                      assembly = "atonsa", # this is just a string. no actual database
                      dbtype = "tabix",
                      context = "CpG",
                      resolution = "base",
                      mincov = 20,
                            treatment = 
                              c(0,0,0,0,
                                1,1,1,1,
                                2,2,2,2,
                                3,3,3,3,
                                4,4,4,4),
                      pipeline = "bismarkCoverage",
                      )

######
# visualize coverage and filter
######

# We can look at the coverage for individual samples with getCoverageStats()

getCoverageStats(myobj[[1]], plot = TRUE)

# and can plot all of our samples at once to compare.


# filter samples by depth with filterByCoverage()
filtered.myobj <- filterByCoverage(myobj,
                  lo.count=20, lo.perc = NULL
                  hi.count=NULL, hi.perc = 97.5)

######
# merge samples
######

#Note! This takes a while and we're skipping it

# use unite() to merge all the samples. We will require sites to be present in each sample or else will drop it

meth <- unite(filtered.myobj,mc.cores=3,
        suffix="united")

meth <- methylKit:::readMethylBaseDB()

# percMethylation() calculates the percent methylation for each site and sample

pm <- percMethylation(meth)

#plot methylation histograms

ggplot(gather(as.data.frame(pm)), aes(value)) + 
    geom_histogram(bins = 10, color="black", fill="grey") + 
    facet_wrap(~key)

# calculate and plot mean methylation

sp/means <- colMeans(pm)

p.df <- data.frame(sample=names(sp.means),
          group = substr(names(sp.means), 1,6),
          methylation = sp.means)
ggplot(p.df, aes(x=group, y=methylation, color=group)) + 
    stat_summary(color="black") + geom_jitter(width=0.1, size=3) 

# sample clustering

clusterSamples(meth, dist="correlation", methog="ward.D", plot = TRUE)

# PCA

PCASamples()

# subset with reorganize()

meth_sub <- reorganize(meth,
                sample.ids =c("AA_F00_1","AA_F00_2","AA_F00_3", "AA_F00_4",
                              "HH_F25_1","HH_F25_2","HH_F25_3","HH_F25_4"),
                treatment = c(0,0,0,0,1,1,1,1),
                save.db=FALSE)
                             
# calculate differential methylation

myDiff <- calculateDiffMeth(meth_sub,
          overdispersion="MN",
          mc.cores = 1, 
          suffix ="AA_HH"
          adjust = "qvalue", 
          test = "Chisq)

# get all differentially methylated bases

myDiff <- getMethylDiff(myDiff, qvalue = 0.05, difference = 10) 

# we can visualize the changes in methylation frequencies quickly.

hist(getData(myDiff)$meth.diff)

# get hyper methylated bases

# get hypo methylated bases

#heatmaps first

# get percent methylation matrix

pm <- percMethylation(meth_sub)
# make a dataframe with snp id's, methylation, etc.
sig.in <- as.numeric(row.names(myDiff))
pm.sig <- pm[sig.in,]

 

# add snp, chr, start, stop

 

din <- getData(myDiff)[,1:3]
df.out <- cbind(paste(getData(myDiff)$chr, getData(myDiff)$start, sep=":"), din, pm.sig)
colnames(df.out) <- c("snp", colnames(din), colnames(df.out[5:ncol(df.out)]))
df.out <- (cbind(df.out,getData(myDiff)[,5:7]))

####
# heatmap
####

my_heatmap <- pheatmap(pm.sig, show_rownames = FALSE)

# we can also normalize 

ctrmean <- rowMeans(pm.sig[,1:4])
h.norm <- (pm.sig-ctrmean)

my_heatmap <- pheatmap(h.norm, show_rownames = FALSE)

------    
<div id='id-section20'/>   


### Entry 20: 2020-02-07, Friday.   



------    
<div id='id-section21'/>   


### Entry 21: 2020-02-10, Monday.   



------    
<div id='id-section22'/>   


------    
<div id='id-section23'/>   


### Entry 23: 2020-02-12, Wednesday.   



------    
<div id='id-section24'/>   


### Entry 24: 2020-02-13, Thursday.   



------  
<div id='id-section'/>   


### Entry 25: 2020-02-14, Friday.   



------    
<div id='id-section26'/>   


### Entry 26: 2020-02-17, Monday.   



------    
<div id='id-section80'/>   


### Entry 27: 2020-02-18, Tuesday.   



------    
<div id='id-section'/>   


### Entry 28: 2020-02-19, Wednesday.   



------    
<div id='id-section29'/>   


### Entry 29: 2020-02-20, Thursday.   



------    
<div id='id-section'/>   


### Entry 30: 2020-02-21, Friday.   



------    
<div id='id-section31'/>   


### Entry 31: 2020-02-24, Monday.   



------    
<div id='id-section32'/>   


### Entry 32: 2020-02-25, Tuesday.   



------    
<div id='id-section33'/>   


### Entry 33: 2020-02-26, Wednesday.   



------    
<div id='id-section34'/>   


### Entry 34: 2020-02-27, Thursday.   



------    
<div id='id-section35'/>   


### Entry 35: 2020-02-28, Friday.   



------    
<div id='id-section36'/>   


### Entry 36: 2020-03-02, Monday.   



------    
<div id='id-section37'/>   


### Entry 37: 2020-03-03, Tuesday.   



------    
<div id='id-section38'/>   


### Entry 38: 2020-03-04, Wednesday.   



------    
<div id='id-section39'/>   


### Entry 39: 2020-03-05, Thursday.   



------    
<div id='id-section40'/>   


### Entry 40: 2020-03-06, Friday.   



------    
<div id='id-section41'/>   


### Entry 41: 2020-03-09, Monday.   



------    
<div id='id-section42'/>   


### Entry 42: 2020-03-10, Tuesday.   



------    
<div id='id-section43'/>   


### Entry 43: 2020-03-11, Wednesday.   



------    
<div id='id-section44'/>   


### Entry 44: 2020-03-12, Thursday.   



------    
<div id='id-section45'/>   


### Entry 45: 2020-03-13, Friday.   



------    
<div id='id-section46'/>   


### Entry 46: 2020-03-16, Monday.   



------    
<div id='id-section47'/>   


### Entry 47: 2020-03-17, Tuesday.   



------    
<div id='id-section48'/>   


### Entry 48: 2020-03-18, Wednesday.   



------    
<div id='id-section49'/>   


### Entry 49: 2020-03-19, Thursday.   



------    
<div id='id-section50'/>   


### Entry 50: 2020-03-20, Friday.   



------    
<div id='id-section51'/>   


### Entry 51: 2020-03-23, Monday.   



------    
<div id='id-section52'/>   


### Entry 52: 2020-03-24, Tuesday.   



------    
<div id='id-section53'/>   


### Entry 53: 2020-03-25, Wednesday.   



------    
<div id='id-section54'/>   


### Entry 54: 2020-03-26, Thursday.   



------    
<div id='id-section55'/>   


### Entry 55: 2020-03-27, Friday.   



------    
<div id='id-section56'/>   


### Entry 56: 2020-03-30, Monday.   



------    
<div id='id-section57'/>   


### Entry 57: 2020-03-31, Tuesday.   



------    
<div id='id-section58'/>   


### Entry 58: 2020-04-01, Wednesday.   



------    
<div id='id-section59'/>   


### Entry 59: 2020-04-02, Thursday.   



------    
<div id='id-section60'/>   


### Entry 60: 2020-04-03, Friday.   



------    
<div id='id-section61'/>   


### Entry 61: 2020-04-06, Monday.   



------    
<div id='id-section62'/>   


### Entry 62: 2020-04-07, Tuesday.   



------    
<div id='id-section63'/>   


### Entry 63: 2020-04-08, Wednesday.   



------    
<div id='id-section64'/>   


### Entry 64: 2020-04-09, Thursday.   



------    
<div id='id-section65'/>   


### Entry 65: 2020-04-10, Friday.   



------    
<div id='id-section66'/>   


### Entry 66: 2020-04-13, Monday.   



------    
<div id='id-section67'/>   


### Entry 67: 2020-04-14, Tuesday.   



------    
<div id='id-section68'/>   


### Entry 68: 2020-04-15, Wednesday.   



------    
<div id='id-section69'/>   


### Entry 69: 2020-04-16, Thursday.   



------    
<div id='id-section70'/>   


### Entry 70: 2020-04-17, Friday.   



------    
<div id='id-section71'/>   


### Entry 71: 2020-04-20, Monday.   



------    
<div id='id-section72'/>   


### Entry 72: 2020-04-21, Tuesday.   



------    
<div id='id-section73'/>   


### Entry 73: 2020-04-22, Wednesday.   



------    
<div id='id-section74'/>   


### Entry 74: 2020-04-23, Thursday.   



------    
<div id='id-section75'/>   


### Entry 75: 2020-04-24, Friday.   



------    
<div id='id-section76'/>   


### Entry 76: 2020-04-27, Monday.   



------    
<div id='id-section77'/>   


### Entry 77: 2020-04-28, Tuesday.   



------    
<div id='id-section78'/>   


### Entry 78: 2020-04-29, Wednesday.   



------    
<div id='id-section79'/>   


### Entry 79: 2020-04-30, Thursday.   



------    
<div id='id-section80'/>   


### Entry 80: 2020-05-01, Friday.   



------    
<div id='id-section81'/>   


### Entry 81: 2020-05-04, Monday.   



------    
<div id='id-section82'/>   


### Entry 82: 2020-05-05, Tuesday.   



------    
<div id='id-section83'/>   


### Entry 83: 2020-05-06, Wednesday.   



------    
<div id='id-section84'/>   


### Entry 84: 2020-05-07, Thursday.   



------    
<div id='id-section85'/>   


### Entry 85: 2020-05-08, Friday.   
